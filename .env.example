# MCP SSE Server Configuration Example
# Copy this file to .env and fill in your actual values

# Required Configuration
# ======================

# Authentication key for MCP server requests
# Generate a secure random string for production
MCP_SERVER_AUTH_KEY=secure-api-key-for-mcp-demo-2

# Optional Configuration
# ======================

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Environment name (development, staging, production)
ENVIRONMENT=development

# Enable file logging (true/false)
FILE_LOGGING=true

# Directory for log files (relative to project root)
LOGS_DIR=logs

# Deployment Configuration
# ========================

# Base name for Azure resources (used for deployment)
BASE_NAME=mcp-sse

# Azure region code for resource naming
REGION_CODE=san

# Azure Key Vault Configuration
# ==============================

# Azure Key Vault URL
# Format: https://{vault-name}.vault.azure.net/
AZURE_KEY_VAULT_URL=https://your-kevault.vault.azure.net/

# Name of the secret in Key Vault that contains the LLM API key
LLM_API_KEY_SECRET_NAME=YOUR-LLM-API-KEY-SECRET-NAME

# LLM API Configuration
# ====================

# Base URL for LLM API calls (default: OpenAI)
LLM_BASE_URL=https://api.openai.com/v1

# LLM model to use for concurrent calls
# Valid models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo, etc.
LLM_MODEL=gpt-5-nano

# LLM temperature (ignored for gpt-5 models which only support default temperature=1.0)
LLM_TEMPERATURE=0.3

